{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "X Sentiment Analysis using Python\n"
      ],
      "metadata": {
        "id": "J48wesl0TEZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis is a task of natural language processing. All social media platforms should monitor the sentiments of those engaged in a discussion. We mostly see negative opinions on Twitter when the discussion is political. So, each platform should continue to analyze the sentiments to find the type of people who are spreading hate and negativity on their platform.\n",
        "\n",
        "For the task of Twitter sentiment analysis, I have collected a dataset from Kaggle that contains tweets about a long discussion within a group of users. Here our task is to identify how many tweets are negative and positive so that we can give a conclusion. So, in the section below, I’m going to introduce you to a task of Twitter sentiment analysis using Python."
      ],
      "metadata": {
        "id": "4T5AUOdjTHmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z3AwdHE7R4QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621e2c4b-20eb-441e-81c7-2980e03214ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    id  user_name user_location           user_description  \\\n",
            "0  1544379368478212100  Elon Musk           NaN  Mars & Cars, Chips & Dips   \n",
            "1  1544377493263720450  Elon Musk           NaN  Mars & Cars, Chips & Dips   \n",
            "2  1544377130590552064  Elon Musk           NaN  Mars & Cars, Chips & Dips   \n",
            "3  1544375575724400645  Elon Musk           NaN  Mars & Cars, Chips & Dips   \n",
            "4  1544375148605853699  Elon Musk           NaN  Mars & Cars, Chips & Dips   \n",
            "\n",
            "                user_created  user_followers  user_friends  user_favourites  \\\n",
            "0  2009-06-02 20:12:29+00:00       101240855           115            13503   \n",
            "1  2009-06-02 20:12:29+00:00       101240806           115            13503   \n",
            "2  2009-06-02 20:12:29+00:00       101240806           115            13503   \n",
            "3  2009-06-02 20:12:29+00:00       101240806           115            13503   \n",
            "4  2009-06-02 20:12:29+00:00       101240806           115            13503   \n",
            "\n",
            "   user_verified                       date  \\\n",
            "0           True  2022-07-05 17:55:09+00:00   \n",
            "1           True  2022-07-05 17:47:42+00:00   \n",
            "2           True  2022-07-05 17:46:15+00:00   \n",
            "3           True  2022-07-05 17:40:05+00:00   \n",
            "4           True  2022-07-05 17:38:23+00:00   \n",
            "\n",
            "                                                text hashtags  \\\n",
            "0  @BillyM2k I find the gold toe sock – inevitabl...      NaN   \n",
            "1                 Sock Con, the conference for socks      NaN   \n",
            "2  Always something new for the magazine cover an...      NaN   \n",
            "3                   @ExplainThisBob This guy gets it      NaN   \n",
            "4  Sock tech is so advanced that you can get pret...      NaN   \n",
            "\n",
            "               source  retweets  favorites  is_retweet  \n",
            "0  Twitter for iPhone       335       6542       False  \n",
            "1  Twitter for iPhone      1451      30753       False  \n",
            "2  Twitter for iPhone      1284      28610       False  \n",
            "3  Twitter for iPhone       131       3640       False  \n",
            "4  Twitter for iPhone      1191      23790       False  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import re\n",
        "import nltk\n",
        "import nltk\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/elon_musk_tweets.csv\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tweet column in the above dataset contains the tweets that we need to use to analyze the feelings of those engaged in the discussion. But to go further, we have to clean up a lot of errors and other special symbols because these tweets contain a lot of language errors. So here is how we can clean up the tweet column:\n"
      ],
      "metadata": {
        "id": "7Bg4154XUWv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text\n",
        "\n",
        "# Replace 'Tweets' with the actual column name from data.columns output\n",
        "data[\"text\"] = data[\"text\"].apply(clean) # Apply clean function to the correct column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MkKQ_cTUXps",
        "outputId": "94c57a0c-38ad-494c-f831-84e091b8a137"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the next step is to calculate the sentiment scores of these tweets and assign a label to the tweets as positive, negative, or neutral. Here is how you can calculate the sentiment scores of the tweets:"
      ],
      "metadata": {
        "id": "7qRC2teHU35R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sentiments = SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"text\"]]\n",
        "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"text\"]]\n",
        "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"text\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV1MEdNXU4Wr",
        "outputId": "cdc05a20-15a4-4ba4-a899-a5496f3e88cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will only select the columns from this data that we need for the rest of the task of Twitter sentiment analysis:"
      ],
      "metadata": {
        "id": "04vQrBQyVAyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"text\", \"Positive\",\n",
        "             \"Negative\", \"Neutral\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwso4Fp6VBOq",
        "outputId": "8f4022ac-e94f-4e8c-8f1c-49251b500a3d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  Positive  Negative  \\\n",
            "0   find gold toe sock – inevit kilter amp wash –...       0.0       0.0   \n",
            "1                               sock con confer sock       0.0       0.0   \n",
            "2  alway someth new magazin cover articl practic ...       0.0       0.0   \n",
            "3                             explainthisbob guy get       0.0       0.0   \n",
            "4  sock tech advanc get pretti much anyth sock fo...       0.0       0.0   \n",
            "\n",
            "   Neutral  \n",
            "0      1.0  \n",
            "1      1.0  \n",
            "2      1.0  \n",
            "3      1.0  \n",
            "4      1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s have a look at the most frequent label assigned to the tweets according to the sentiment scores:"
      ],
      "metadata": {
        "id": "vYiiXPF6VHlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = sum(data[\"Positive\"])\n",
        "y = sum(data[\"Negative\"])\n",
        "z = sum(data[\"Neutral\"])\n",
        "\n",
        "def sentiment_score(a, b, c):\n",
        "    if (a>b) and (a>c):\n",
        "        print(\"Positive 😊 \")\n",
        "    elif (b>a) and (b>c):\n",
        "        print(\"Negative 😠 \")\n",
        "    else:\n",
        "        print(\"Neutral 🙂 \")\n",
        "sentiment_score(x, y, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNj1vLXnVIW3",
        "outputId": "49bd8564-ba9b-499e-b09b-abf45bdfc470"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral 🙂 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the most of the tweets are neutral, which means they are neither positive nor negative. Now let’s have a look at the total of the sentiment scores:"
      ],
      "metadata": {
        "id": "OdS1lp6MVMPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Positive: \", x)\n",
        "print(\"Negative: \", y)\n",
        "print(\"Neutral: \", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShdLzbCKVMrV",
        "outputId": "9bc1d813-1e1b-4213-d5c2-ffe30083a7d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive:  969.3199999999972\n",
            "Negative:  325.2209999999998\n",
            "Neutral:  4584.47199999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total of neutral is way higher than negative and positive, but out of all the tweets, the negative tweets are more than the positive tweets, so we can say that most of the opinions are negative.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "So this is how you can perform the task of Twitter sentiment analysis by using the Python programming language. Analyzing sentiments is a task of natural language processing. All the social media platforms need to keep a check on the sentiments of people engaged in a discussion."
      ],
      "metadata": {
        "id": "2uJbH9sYVReu"
      }
    }
  ]
}